{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Objective:**\n",
        "- WAP to implement a multi-layer perceptron (MLP) network with one hidden layer using numpy in Python. Demonstrate that it can learn the XOR Boolean function."
      ],
      "metadata": {
        "id": "P9TdAVdDocQs"
      },
      "id": "P9TdAVdDocQs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Description of the Model:**\n",
        "- This is a Multi-Layer Perceptron (MLP) with a single hidden layer and a step activation function.\n",
        "- It is trained using backpropagation and attempts to learn the XOR function."
      ],
      "metadata": {
        "id": "9xAnXGzWORq-"
      },
      "id": "9xAnXGzWORq-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Python Implementation**"
      ],
      "metadata": {
        "id": "J6rizhYCMFji"
      },
      "id": "J6rizhYCMFji"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "17adaff8-23c0-4f38-92ac-965aa302f9aa",
      "metadata": {
        "id": "17adaff8-23c0-4f38-92ac-965aa302f9aa",
        "outputId": "76ba7927-8961-45ec-9c6f-a1cc780dfe85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MLP for XOR\n",
            "Accuracy: 75.00%\n",
            "Confusion Matrix:\n",
            "[[1 1]\n",
            " [0 2]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1],\n",
              "       [0, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "class MLP_XOR:\n",
        "    def __init__(self, input_size, hidden_size, lr=0.1, epochs=10000):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "        # Initialize weights for input to hidden and hidden to output layers\n",
        "        self.W1 = np.random.randn(self.hidden_size, self.input_size + 1)  # +1 for bias\n",
        "        self.W2 = np.random.randn(1, self.hidden_size + 1)  # +1 for bias\n",
        "\n",
        "    def activation(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = np.insert(x, 0, 1)  # Adding bias\n",
        "        self.h_input = np.dot(self.W1, x)\n",
        "        self.h_output = np.array([self.activation(h) for h in self.h_input])\n",
        "        self.h_output = np.insert(self.h_output, 0, 1)  # Adding bias for hidden layer\n",
        "\n",
        "        self.o_input = np.dot(self.W2, self.h_output)\n",
        "        self.o_output = self.activation(self.o_input)\n",
        "        return self.o_output\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for _ in range(self.epochs):\n",
        "            for xi, target in zip(X, y):\n",
        "                xi = np.insert(xi, 0, 1)  # Adding bias\n",
        "\n",
        "                # Forward pass\n",
        "                h_input = np.dot(self.W1, xi)\n",
        "                h_output = np.array([self.activation(h) for h in h_input])\n",
        "                h_output = np.insert(h_output, 0, 1)  # Adding bias\n",
        "\n",
        "                o_input = np.dot(self.W2, h_output)\n",
        "                o_output = self.activation(o_input)\n",
        "\n",
        "                # Compute error\n",
        "                error = target - o_output\n",
        "\n",
        "                # Backpropagation - Update weights\n",
        "                self.W2 += self.lr * error * h_output\n",
        "                self.W1 += self.lr * error * np.outer((self.W2[:, 1:] > 0), xi)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predictions = [self.forward(x) for x in X]\n",
        "        correct = sum(p == t for p, t in zip(predictions, y))\n",
        "        accuracy = correct / len(y) * 100\n",
        "        print(f'Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "        # Compute confusion matrix\n",
        "        cm = confusion_matrix(y, predictions)\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(cm)\n",
        "        return cm\n",
        "\n",
        "# XOR Truth Table\n",
        "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_xor = np.array([0, 1, 1, 0])\n",
        "\n",
        "# Train MLP on XOR using step function\n",
        "print(\"Training MLP for XOR\")\n",
        "mlp_xor = MLP_XOR(input_size=2, hidden_size=2, lr=0.1, epochs=1000)\n",
        "mlp_xor.train(X_xor, y_xor)\n",
        "mlp_xor.evaluate(X_xor, y_xor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Code Explanation:**\n"
      ],
      "metadata": {
        "id": "NvYsnuiXOc73"
      },
      "id": "NvYsnuiXOc73"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**My Comments:**\n",
        "1. The step activation function is not ideal for backpropagation since it lacks smooth gradients.\n",
        "2. This MLP can learn XOR, but convergence is slower and less stable than using sigmoid or ReLU.\n",
        "3. The weight update could be improved with momentum or adaptive learning rates.\n",
        "4. Using sigmoid/ReLU activation would allow better gradient flow and training efficiency.\n",
        "5. The training process could benefit from batch updates rather than single-sample updates."
      ],
      "metadata": {
        "id": "ZsCkeUd5Ofay"
      },
      "id": "ZsCkeUd5Ofay"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7585c30-50d9-4c1e-af78-c07334909b84",
      "metadata": {
        "id": "c7585c30-50d9-4c1e-af78-c07334909b84"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
